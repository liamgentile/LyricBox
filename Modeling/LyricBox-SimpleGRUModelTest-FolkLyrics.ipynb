{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f15b34",
   "metadata": {},
   "source": [
    "# In this notebook I make a simple sequential neural network with GRU layers  and model the folk lyric dataset. This will serve as a jumping off point for future, more complex modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715d4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load up some libraries\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GRU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045ed18",
   "metadata": {},
   "source": [
    "I'll start by importing the folk DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd0e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "folk_df = pd.read_pickle('/Users/liamgentile/Desktop/folk_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f23332",
   "metadata": {},
   "source": [
    "Let's take a quick look to make sure it looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5053464e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Living on free food tickets. Water in the mil...</td>\n",
       "      <td>theloveofcommonpeople</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>Living on free food tickets. Water in the milk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Do you remember days not so very long ago, wh...</td>\n",
       "      <td>catchanotherbutterfly</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>Do you remember days not so very long ago, whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Yes, I been dreaming about you every day, eac...</td>\n",
       "      <td>daydream</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>Yes, I been dreaming about you every day, each...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I'll sing you a song of Spiro Agnew and all t...</td>\n",
       "      <td>theballadofspiroagnew</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>I'll sing you a song of Spiro Agnew and all th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[If I look like home to you, if I am your sign...</td>\n",
       "      <td>circus</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>If I look like home to you, if I am your sign,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics                   song  \\\n",
       "0  [Living on free food tickets. Water in the mil...  theloveofcommonpeople   \n",
       "1  [Do you remember days not so very long ago, wh...  catchanotherbutterfly   \n",
       "2  [Yes, I been dreaming about you every day, eac...               daydream   \n",
       "3  [I'll sing you a song of Spiro Agnew and all t...  theballadofspiroagnew   \n",
       "4  [If I look like home to you, if I am your sign...                 circus   \n",
       "\n",
       "       artist                                      lyrics_string  \n",
       "0  johndenver  Living on free food tickets. Water in the milk...  \n",
       "1  johndenver  Do you remember days not so very long ago, whe...  \n",
       "2  johndenver  Yes, I been dreaming about you every day, each...  \n",
       "3  johndenver  I'll sing you a song of Spiro Agnew and all th...  \n",
       "4  johndenver  If I look like home to you, if I am your sign,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folk_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7639d1c",
   "metadata": {},
   "source": [
    "Now let's create a new column in which all special characters and punctuation have been removed from the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db4d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-4721f3564bdd>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  folk_df[\"Content\"] = folk_df[\"lyrics_string\"].str.replace(r\"[^a-zA-Z]\", \" \").str.replace(r\"\\s+\", \" \")\n"
     ]
    }
   ],
   "source": [
    "# the second replace just removes repeated whitespaces\n",
    "folk_df[\"Content\"] = folk_df[\"lyrics_string\"].str.replace(r\"[^a-zA-Z]\", \" \").str.replace(r\"\\s+\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf399b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics_string</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Living on free food tickets. Water in the mil...</td>\n",
       "      <td>theloveofcommonpeople</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>Living on free food tickets. Water in the milk...</td>\n",
       "      <td>Living on free food tickets Water in the milk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Do you remember days not so very long ago, wh...</td>\n",
       "      <td>catchanotherbutterfly</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>Do you remember days not so very long ago, whe...</td>\n",
       "      <td>Do you remember days not so very long ago when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Yes, I been dreaming about you every day, eac...</td>\n",
       "      <td>daydream</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>Yes, I been dreaming about you every day, each...</td>\n",
       "      <td>Yes I been dreaming about you every day each a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I'll sing you a song of Spiro Agnew and all t...</td>\n",
       "      <td>theballadofspiroagnew</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>I'll sing you a song of Spiro Agnew and all th...</td>\n",
       "      <td>I ll sing you a song of Spiro Agnew and all th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[If I look like home to you, if I am your sign...</td>\n",
       "      <td>circus</td>\n",
       "      <td>johndenver</td>\n",
       "      <td>If I look like home to you, if I am your sign,...</td>\n",
       "      <td>If I look like home to you if I am your sign d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics                   song  \\\n",
       "0  [Living on free food tickets. Water in the mil...  theloveofcommonpeople   \n",
       "1  [Do you remember days not so very long ago, wh...  catchanotherbutterfly   \n",
       "2  [Yes, I been dreaming about you every day, eac...               daydream   \n",
       "3  [I'll sing you a song of Spiro Agnew and all t...  theballadofspiroagnew   \n",
       "4  [If I look like home to you, if I am your sign...                 circus   \n",
       "\n",
       "       artist                                      lyrics_string  \\\n",
       "0  johndenver  Living on free food tickets. Water in the milk...   \n",
       "1  johndenver  Do you remember days not so very long ago, whe...   \n",
       "2  johndenver  Yes, I been dreaming about you every day, each...   \n",
       "3  johndenver  I'll sing you a song of Spiro Agnew and all th...   \n",
       "4  johndenver  If I look like home to you, if I am your sign,...   \n",
       "\n",
       "                                             Content  \n",
       "0  Living on free food tickets Water in the milk ...  \n",
       "1  Do you remember days not so very long ago when...  \n",
       "2  Yes I been dreaming about you every day each a...  \n",
       "3  I ll sing you a song of Spiro Agnew and all th...  \n",
       "4  If I look like home to you if I am your sign d...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folk_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a40961",
   "metadata": {},
   "source": [
    "Now I will fit tensorflow.keras' tokenizer to the lyrics. I will be doing word based vectorization and i'll set lower to True in order to make all the text lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab94c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: char_level is False now\n",
    "tokenizer = Tokenizer(char_level=False, lower=True) \n",
    "tokenizer.fit_on_texts(folk_df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1374199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 27457\n"
     ]
    }
   ],
   "source": [
    "word_to_number = tokenizer.word_index\n",
    "number_to_word = tokenizer.index_word\n",
    "\n",
    "all_words = list(word_to_number.keys())\n",
    "\n",
    "print(f\"Vocabulary size: {len(all_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c1c0e",
   "metadata": {},
   "source": [
    "Wow! We have a vocabulary of 27,457 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29200976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the data to sequences\n",
    "dataset = tokenizer.texts_to_sequences(folk_df[\"Content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b95de",
   "metadata": {},
   "source": [
    "Now I'll set the window length for the arrays that will make up the input for the neural network. I'll set a sequence length of 7, which seemed to work reasonably well in the text data lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52245712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1397954, 7)\n",
      "(1397954,)\n"
     ]
    }
   ],
   "source": [
    "# sliding window\n",
    "SEQUENCE_LENGTH = 7\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for song in dataset:\n",
    "    for window_start_idx in range(len(song)-SEQUENCE_LENGTH):\n",
    "        window_end_idx = window_start_idx + SEQUENCE_LENGTH\n",
    "        X.append(song[window_start_idx: window_end_idx])\n",
    "        y.append(song[window_end_idx])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Let's look at the shapes\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0b77c4",
   "metadata": {},
   "source": [
    "1,397,954 X 7. That is a large X array!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75031a",
   "metadata": {},
   "source": [
    "Now let's split the data into train and validation so we can monitor overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "972fe911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split train and validation set\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc95f7c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258158, 7) (1258158,)\n",
      "(139796, 7) (139796,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)      \n",
    "print(X_validation.shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9718bb2",
   "metadata": {},
   "source": [
    "Now i'll arrange the structural of the sequential neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d55926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(all_words)+1\n",
    "\n",
    "RNN_wordlevel = Sequential()\n",
    "\n",
    "RNN_wordlevel.add(Embedding(number_of_classes, 8))\n",
    "\n",
    "# the intermediate recurrent layers should return full sequences\n",
    "RNN_wordlevel.add(GRU(64, activation='relu', return_sequences=True))\n",
    "RNN_wordlevel.add(BatchNormalization())\n",
    "RNN_wordlevel.add(Dropout(0.15))\n",
    "\n",
    "# the last recurrent layer only returns the final output\n",
    "RNN_wordlevel.add(GRU(32, activation='relu', return_sequences=False))\n",
    "RNN_wordlevel.add(BatchNormalization())\n",
    "RNN_wordlevel.add(Dropout(0.15))\n",
    "\n",
    "RNN_wordlevel.add(Dense(16, activation='relu'))\n",
    "RNN_wordlevel.add(BatchNormalization())\n",
    "RNN_wordlevel.add(Dropout(0.15))\n",
    "\n",
    "RNN_wordlevel.add(Dense(number_of_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f69370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "RNN_wordlevel.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(lr=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a4b379d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 8)           219664    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 64)          14208     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                9408      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 27458)             466786    \n",
      "=================================================================\n",
      "Total params: 711,042\n",
      "Trainable params: 710,818\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display its summary\n",
    "RNN_wordlevel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50189b56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1229/1229 [==============================] - 485s 395ms/step - loss: 6.7226 - accuracy: 0.0863 - val_loss: 5.6694 - val_accuracy: 0.1220\n",
      "Epoch 2/2\n",
      "1229/1229 [==============================] - 486s 395ms/step - loss: 5.6758 - accuracy: 0.1210 - val_loss: 5.4947 - val_accuracy: 0.1379\n"
     ]
    }
   ],
   "source": [
    "history = RNN_wordlevel.fit(X_train, y_train,\n",
    "        batch_size=1024,\n",
    "        epochs=2,\n",
    "        validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf0900",
   "metadata": {},
   "source": [
    "## I originally ran this data model for 50 epochs or so, but I accidentally left the notebook before saving the model. So when going back to generate some text I lost my progress. I started another model with 2 epochs just to demonstrate the generate_text function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25bcdf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "RNN_wordlevel.save('Dbasic_seqmodel_wGRU_folklyrics.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b2febbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_phrase, next_words, model):\n",
    "    # process for the model\n",
    "    processed_phrase = tokenizer.texts_to_sequences([input_phrase])[0]\n",
    "    for i in range(next_words):\n",
    "      network_input = np.array(processed_phrase[-(len(processed_phrase)):], dtype=np.float32)\n",
    "      network_input = network_input.reshape((1, (len(processed_phrase)))) # shape: 1 x 7\n",
    "\n",
    "      # the RNN gives the probability of each word as the next one\n",
    "      predict_proba = model.predict(network_input)[0] # shape (4855,)\n",
    "      \n",
    "      # sample one word using these chances\n",
    "      predicted_index = np.random.choice(number_of_classes, 1, p=predict_proba)[0]\n",
    "\n",
    "      # add new index at the end of our list\n",
    "      processed_phrase.append(predicted_index)\n",
    "      \n",
    "\n",
    "  # indices mapped to words - the method expects a list of lists so we need the extra bracket\n",
    "      output_phrase = tokenizer.sequences_to_texts([processed_phrase])[0]\n",
    "\n",
    "    return output_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39683a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love life live not at substitute town but she go to me where you will just find him anymore who don'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"love\", 20, RNN_wordlevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3007e",
   "metadata": {},
   "source": [
    "Considering the relative simplicity of the model and the small number of epochs, this is quite promising. I am optimistic about the future potential of modeling in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b34ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
